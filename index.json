{"project": "project", "project_url": "#", "show_commit_url": "#", "hash_length": 8, "revision_to_hash": {"140": "67cc78c8ee15cdf067523da1ef33a252e72dc996", "231": "c320991aaf686dc676209e01525fca91e8717f88", "478": "d757a3a36dfb71c577406a3aca3db1dd2c82d014", "568": "9caa55a8cd5c6785c5c5198593a7a2ce0b2691c4", "756": "e36a2415e15d7abbc8646eb1986f9c2fe211b03f", "972": "56546c4ce48e01392d9027eb7d14243507aca2a1", "1015": "ced6fc9fb4d3ed4d5d45fd0ea672b550b4ab0907", "1173": "681a46d7d7b6184fa848920294d986a2dcf5708f", "1408": "44aa33437fab1392cd6bda9457b1dae44d977b96", "1531": "bcbebc7ba3ae63bf3f25c3db921e3002b363bf27", "1665": "d3b015a82b4af721df8f633e88789eca339b8f93", "1838": "bf8d50ae4e119e7b47ec83e285c9b8b641a1631d", "1844": "950de751019e9c3b72f3a07425618d56602ecd67", "1984": "1f0a71cf36141653f933bdc1db7ddc0fa8513447", "2060": "b52146ba91a784d94a2dc47d340fe2c71c00a5dc", "2129": "9279b0654b5dd6f35cebae2dde127b642f29ee91", "2130": "551e30b19ee4737bdf69a6a9a7044070ba8038fc", "2183": "f3dd9107cb90c22030770441dbf0f37262be3591", "2215": "6080e21e4306f5bc62852fa255259e9ffe70a4d8", "2286": "f9e8484fc000f66805ab9fdb4926dcd5d30ad1ca", "2356": "9a0e202c2e0c71184d817e4be3824b7af4055e62", "2735": "df6bfb89ce31fb4f0a2de0b790ac453d72432f80", "2762": "c073bd11de11dc0ef3e4988b6d584dce78ce4c02", "2827": "4c2752b308000c9b5800cc8def3e72494cfc6ea3", "2926": "03f869c18c51bcb9bc49eaf7fbdc00f1900820f1", "2929": "0764ef188637a8c89b6a82a10bc1153918fa9d54", "3149": "c36e7b4cdb416d237842480aaf9e9b6cac41f194", "3405": "595b58dc72f91265030363e230f710b90cde1e60", "3710": "2e342b41ca8dcb2a09dc199ab6920bb50bf7542b", "3844": "6b5bc89c52128c68a85c704bca2506f23d6f9d57", "4054": "ee60db610ca035dd713cbe92c33ff16efffaf1a9", "4065": "e0e2784135f7e6d8253b396ea5fbb3adf54d496c", "4800": "4e5f510fb4c9f15177146bd336133b468e7b207c", "5030": "86b67f89526e6e783365e8dc69828664fe4470c5", "5193": "aba238d45f92af4a6bc3f3c6b02650584a5d81da", "5195": "d6c0ce1d9cc8d0eccb5fc942045d7431815e9fa6", "5511": "8fd089556aa58fe23dc1d24b08f1023cda1e759e", "5855": "b4bd746b240864727997778c1b83caf5d69b2231", "5905": "f9372a117b6e58910eff1cb379aa7ec943b2789e", "5971": "ba81d454f8eba6edd5e1a3f9d4f58c29c0c321e5", "6157": "baea2cb313567fbd34d02c67980145e32ead4b15", "6167": "a40f25b5d4912ebd1b9d23a163b7be1542e1cda9", "6171": "24181ddc4a14705b8e945ffc8276bc4fff23081a", "6211": "82f41b23085ba1ffede7ff5b3b69a53cf5d5c05b", "6236": "19c387b169960484f8733dd233e09e3abf0a7966"}, "revision_to_date": {"140": 1634109321000, "231": 1634135442000, "478": 1635673631000, "568": 1636068929000, "756": 1636904342000, "972": 1637581559000, "1015": 1637702043000, "1173": 1638272902000, "1408": 1639068335000, "1531": 1639492214000, "1665": 1639998471000, "1838": 1640190892000, "1844": 1640205156000, "1984": 1640851796000, "2060": 1641115165000, "2129": 1641140363000, "2130": 1641141546000, "2183": 1641289727000, "2215": 1641299289000, "2286": 1641395474000, "2356": 1641570342000, "2735": 1642604269000, "2762": 1642677350000, "2827": 1643035046000, "2926": 1643215318000, "2929": 1643217007000, "3149": 1643966186000, "3405": 1644859714000, "3710": 1645634114000, "3844": 1646321927000, "4054": 1646929457000, "4065": 1646950289000, "4800": 1648825067000, "5030": 1649786048000, "5193": 1651127614000, "5195": 1651128801000, "5511": 1652364664000, "5855": 1653830475000, "5905": 1653987622000, "5971": 1654587572000, "6157": 1655638385000, "6167": 1655640835000, "6171": 1655642150000, "6211": 1655734193000, "6236": 1655840676000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"], "machine": ["Itays-MacBook-Pro.local", "ip-192-168-1-9.eu-west-1.compute.internal"], "num_cpu": ["16"], "os": ["Darwin 21.5.0"], "ram": ["34359738368"], "python": ["3.9"], "branch": ["HEAD"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz", "machine": "Itays-MacBook-Pro.local", "num_cpu": "16", "os": "Darwin 21.5.0", "ram": "34359738368", "python": "3.9", "branch": "HEAD"}], "benchmarks": {"benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_BoostingOverfit": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_BoostingOverfit", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_CalibrationScore": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_CalibrationScore", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_CategoryMismatchTrainTest": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_CategoryMismatchTrainTest", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ColumnsInfo": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ColumnsInfo", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ConflictingLabels": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ConflictingLabels", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ConfusionMatrixReport": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ConfusionMatrixReport", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DataDuplicates": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DataDuplicates", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DatasetsSizeComparison": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DatasetsSizeComparison", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DateTrainTestLeakageDuplicates": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DateTrainTestLeakageDuplicates", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DateTrainTestLeakageOverlap": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DateTrainTestLeakageOverlap", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DominantFrequencyChange": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_DominantFrequencyChange", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_FeatureLabelCorrelation": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_FeatureLabelCorrelation", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_FeatureLabelCorrelationChange": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_FeatureLabelCorrelationChange", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_IdentifierLabelCorrelation": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_IdentifierLabelCorrelation", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_IndexTrainTestLeakage": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_IndexTrainTestLeakage", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_IsSingleValue": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_IsSingleValue", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_MixedDataTypes": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_MixedDataTypes", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_MixedNulls": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_MixedNulls", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ModelErrorAnalysis": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ModelErrorAnalysis", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ModelInferenceTime": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ModelInferenceTime", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ModelInfo": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_ModelInfo", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_MultiModelPerformanceReport": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_MultiModelPerformanceReport", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_NewLabelTrainTest": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_NewLabelTrainTest", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_OutlierSampleDetection": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_OutlierSampleDetection", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_PerformanceReport": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_PerformanceReport", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_RegressionErrorDistribution": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_RegressionErrorDistribution", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_RegressionSystematicError": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_RegressionSystematicError", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_RocReport": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_RocReport", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_SegmentPerformance": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_SegmentPerformance", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_SimpleModelComparison": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_SimpleModelComparison", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_SpecialCharacters": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_SpecialCharacters", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_StringLengthOutOfBounds": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_StringLengthOutOfBounds", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_StringMismatch": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_StringMismatch", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_StringMismatchComparison": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_StringMismatchComparison", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_TrainTestFeatureDrift": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_TrainTestFeatureDrift", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_TrainTestLabelDrift": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_TrainTestLabelDrift", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_TrainTestPredictionDrift": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_TrainTestPredictionDrift", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_TrainTestSamplesMix": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_TrainTestSamplesMix", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_UnusedFeatures": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_UnusedFeatures", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_WholeDatasetDrift": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksPeakMemory:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "name": "benchmarks.BenchmarkTabularChecksPeakMemory.peakmem_WholeDatasetDrift", "param_names": ["dataset_name"], "params": [["'iris'"]], "setup_cache_key": "benchmarks:50", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d54cc6b5accc10d2bdb334272d0af6fb2b727c485d9a8d46ec6573d78f7e376"}, "benchmarks.BenchmarkTabularChecksTime.time_BoostingOverfit": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_BoostingOverfit", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_CalibrationScore": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_CalibrationScore", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_CategoryMismatchTrainTest": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_CategoryMismatchTrainTest", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_ColumnsInfo": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_ColumnsInfo", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_ConflictingLabels": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_ConflictingLabels", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_ConfusionMatrixReport": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_ConfusionMatrixReport", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_DataDuplicates": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_DataDuplicates", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_DatasetsSizeComparison": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_DatasetsSizeComparison", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_DateTrainTestLeakageDuplicates": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_DateTrainTestLeakageDuplicates", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_DateTrainTestLeakageOverlap": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_DateTrainTestLeakageOverlap", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_DominantFrequencyChange": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_DominantFrequencyChange", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_FeatureLabelCorrelation": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_FeatureLabelCorrelation", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_FeatureLabelCorrelationChange": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_FeatureLabelCorrelationChange", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_IdentifierLabelCorrelation": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_IdentifierLabelCorrelation", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_IndexTrainTestLeakage": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_IndexTrainTestLeakage", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_IsSingleValue": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_IsSingleValue", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_MixedDataTypes": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_MixedDataTypes", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_MixedNulls": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_MixedNulls", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_ModelErrorAnalysis": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_ModelErrorAnalysis", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_ModelInferenceTime": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_ModelInferenceTime", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_ModelInfo": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_ModelInfo", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_MultiModelPerformanceReport": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_MultiModelPerformanceReport", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_NewLabelTrainTest": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_NewLabelTrainTest", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_OutlierSampleDetection": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_OutlierSampleDetection", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_PerformanceReport": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_PerformanceReport", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_RegressionErrorDistribution": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_RegressionErrorDistribution", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_RegressionSystematicError": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_RegressionSystematicError", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_RocReport": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_RocReport", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_SegmentPerformance": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_SegmentPerformance", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_SimpleModelComparison": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_SimpleModelComparison", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_SpecialCharacters": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_SpecialCharacters", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_StringLengthOutOfBounds": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_StringLengthOutOfBounds", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_StringMismatch": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_StringMismatch", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_StringMismatchComparison": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_StringMismatchComparison", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_TrainTestFeatureDrift": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_TrainTestFeatureDrift", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_TrainTestLabelDrift": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_TrainTestLabelDrift", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_TrainTestPredictionDrift": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_TrainTestPredictionDrift", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_TrainTestSamplesMix": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_TrainTestSamplesMix", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_UnusedFeatures": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_UnusedFeatures", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}, "benchmarks.BenchmarkTabularChecksTime.time_WholeDatasetDrift": {"code": "class <locals>:\n    def run(self, cache, dataset_name):\n        context = cache[dataset_name]\n        check = check_class()\n        try:\n            if isinstance(check, SingleDatasetCheck):\n                check.run_logic(context, DatasetKind.TRAIN)\n            else:\n                check.run_logic(context)\n        except Exception as e:\n            pass\n\nclass BenchmarkTabularChecksTime:\n    def setup_cache(self):\n        cache = {}\n        train, test = iris.load_data()\n        model = iris.load_fitted_model()\n        cache['iris'] = Context(train, test, model)\n        return cache", "min_run_count": 2, "name": "benchmarks.BenchmarkTabularChecksTime.time_WholeDatasetDrift", "number": 0, "param_names": ["dataset_name"], "params": [["'iris'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "benchmarks:37", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6c5f3f52b3c2aec6540005f2cc53b7c204c5955bf5bb08064c55dd109cf969", "warmup_time": -1}}, "machines": {"Itays-MacBook-Pro.local": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz", "machine": "Itays-MacBook-Pro.local", "num_cpu": "16", "os": "Darwin 21.5.0", "ram": "34359738368", "version": 1}, "ip-192-168-1-9.eu-west-1.compute.internal": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz", "machine": "ip-192-168-1-9.eu-west-1.compute.internal", "num_cpu": "16", "os": "Darwin 21.5.0", "ram": "34359738368", "version": 1}}, "tags": {"0.0.10": 1173, "0.0.11": 1408, "0.0.12": 1531, "0.0.13": 1665, "0.0.14": 1838, "0.0.15": 1844, "0.0.16": 1984, "0.0.17": 2060, "0.0.2": 140, "0.0.3": 231, "0.0.4": 478, "0.0.6": 568, "0.0.7": 756, "0.0.8": 972, "0.0.9": 1015, "0.1.0": 2129, "0.1.1": 2130, "0.1.2": 2183, "0.1.3": 2215, "0.2.0": 2286, "0.2.1": 2356, "0.3.0": 2735, "0.3.1": 2762, "0.3.2": 2827, "0.4.0": 2926, "0.4.1": 2929, "0.4.2": 3149, "0.5.0": 3844, "0.5.0.dev0": 3405, "0.5.0.dev2": 3710, "0.6.0": 4800, "0.6.0.dev0": 4054, "0.6.0.dev1": 4065, "0.6.1": 5030, "0.6.2": 5193, "0.6.3": 5195, "0.6.4": 5511, "0.7.0": 5855, "0.7.1": 5905, "0.7.2": 5971, "0.8.0": 6157}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}