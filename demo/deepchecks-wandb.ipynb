{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918574f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd8b5e",
   "metadata": {},
   "source": [
    "## Login W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00589a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"dc-wandb-webinar\"\n",
    "ENTITY_NAME = \"deepchecks\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341205d9",
   "metadata": {},
   "source": [
    "## Load Avocado Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82fa80b",
   "metadata": {},
   "source": [
    "### Get data and save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular import datasets\n",
    "import avocado_dataset_utils\n",
    "\n",
    "data = datasets.regression.avocado.load_data(data_format='DataFrame', as_train_test=False)\n",
    "\n",
    "# a bit preprocessing\n",
    "train_df, test_df = avocado_dataset_utils.get_train_test_df_from_raw(data)\n",
    "label_col_name = 'IsExpensive'\n",
    "categorical_features = ['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f9f09",
   "metadata": {},
   "source": [
    "### Create Dataset\n",
    "\n",
    "So checks have metadata context (label, categorical feature, date column if exists, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cfc61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular import Dataset\n",
    "\n",
    "train_ds = Dataset(train_df, label=label_col_name, cat_features=categorical_features)\n",
    "test_ds = Dataset(test_df, label=label_col_name, cat_features=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48638ab",
   "metadata": {},
   "source": [
    "## Check Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular.suites import single_dataset_integrity\n",
    "\n",
    "integ_suite_results = single_dataset_integrity().run(train_ds)\n",
    "integ_suite_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "integ_suite_results.to_wandb(project=PROJECT_NAME, entity=ENTITY_NAME, name=\"initial-data-integrity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1cc593",
   "metadata": {},
   "source": [
    "### add noise to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd69fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data duplicates, ambiguous labels, string mismatch, ...\n",
    "dirty_train_df = avocado_dataset_utils.add_dirty_data_to_single_df(train_df)\n",
    "dirty_train_ds = Dataset(dirty_train_df, cat_features = categorical_features, label = label_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d5a19f",
   "metadata": {},
   "source": [
    "### Rerun integrity suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9013d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirty_integ_suite_results = single_dataset_integrity().run(dirty_train_ds)\n",
    "dirty_integ_suite_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa0701",
   "metadata": {},
   "source": [
    "#### Log suite results to w&b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cced25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_integ_suite_results.to_wandb(project=PROJECT_NAME, entity=ENTITY_NAME, name=\"dirty-data-integrity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f6028",
   "metadata": {},
   "source": [
    "#### Now lets log (in a new run) specifically checks that didn't pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.core import CheckResult\n",
    "\n",
    "# we want to have them together in one run, so lets init the run:\n",
    "wandb.init(project=PROJECT_NAME, entity=ENTITY_NAME, name=\"integrity-not-passing-checks\")\n",
    "\n",
    "for check_result in dirty_integ_suite_results.results:\n",
    "    if type(check_result) is CheckResult:\n",
    "        if not check_result.passed_conditions():\n",
    "            print(\"Check **{}** didn't Pass. Saving result to wandb\".format(check_result.get_header()))\n",
    "            # Save here to the same run:\n",
    "            check_result.to_wandb(dedicated_run = False)\n",
    "            \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812acdf",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac1810f",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae90dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, train_ohe_columns = avocado_dataset_utils.ohe_for_type_column(train_df)\n",
    "test_df, _ = avocado_dataset_utils.ohe_for_type_column(test_df, train_ohe_columns)\n",
    "\n",
    "train_ds = Dataset(train_df, label=label_col_name, cat_features=[])\n",
    "test_ds = Dataset(test_df, label=label_col_name, cat_features=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8663a73",
   "metadata": {},
   "source": [
    "### Fit & Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ed437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# fit\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(train_ds.features_columns, train_ds.label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde341b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_train = rf_clf.predict(train_ds.features_columns)\n",
    "y_pred_test = rf_clf.predict(test_ds.features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6389c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# minimal metrics check - model accuracty\n",
    "train_acc = accuracy_score(train_ds.label_col, y_pred_train)\n",
    "test_acc = accuracy_score(test_ds.label_col, y_pred_test)\n",
    "print(\"Train accuracy: {}, Test accuracy: {}\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df487c2",
   "metadata": {},
   "source": [
    "### Analyze Splits and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820702be",
   "metadata": {},
   "source": [
    "#### Model Evaluation Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5456e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deepchecks.tabular.suites import model_evaluation\n",
    "\n",
    "me_suite_result = model_evaluation().run(train_ds, test_ds, rf_clf)\n",
    "me_suite_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e807e",
   "metadata": {},
   "source": [
    "#### Run performance report and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular.checks import PerformanceReport\n",
    "\n",
    "perf_result = PerformanceReport().run(train_ds, test_ds, rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eab8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output value\n",
    "perf_result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show \n",
    "perf_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f91a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_result.to_wandb(project=PROJECT_NAME, entity=ENTITY_NAME, name=\"performance-report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900abb8",
   "metadata": {},
   "source": [
    "#### Inspect Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05e614",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from deepchecks.tabular.suites import train_test_validation\n",
    "\n",
    "train_test_validation().run(train_ds, test_ds, rf_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c7ccc",
   "metadata": {},
   "source": [
    "### Run specific checks - separately or in a suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6170ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular.checks import ConfusionMatrixReport, CalibrationScore, DataDuplicates\n",
    "from deepchecks.tabular import Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28530fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_suite = Suite('Custom Evaluation', CalibrationScore(), ConfusionMatrixReport())\n",
    "suite_res = custom_suite.run(train_ds, test_ds, rf_clf)\n",
    "suite_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_res.to_wandb(project=PROJECT_NAME, entity=ENTITY_NAME, name=\"custom-model-eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251bee3c",
   "metadata": {},
   "source": [
    "## Happy, Evaluated and Valid Models and Data...\n",
    "\n",
    "The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
