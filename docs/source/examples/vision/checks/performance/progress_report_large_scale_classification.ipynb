{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# library imports\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "import torch\n",
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# local imports\n",
    "from deepchecks.vision.base import VisionDataset\n",
    "from deepchecks.vision.checks.performance import PerformanceReport\n",
    "from deepchecks.vision.datasets.classification.imagenet import get_trained_imagenet_model, \\\n",
    "    get_imagenet_dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this loads the actual names for imagenet classes\n",
    "# TODO this can be a bit less ugly or contained in dir structure\n",
    "synsets = \"/Users/nirbenzvi/code/DeepChecks/ImageNet/synsets.txt\"\n",
    "with open(synsets, 'r') as fid:\n",
    "    real_class_names = {l.split()[0]: \" \".join(l.split()[1:]).split(\",\")[0].strip() for l in fid}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load dataloaders and model\n",
    "model = get_trained_imagenet_model()\n",
    "_, val_dataloader = get_imagenet_dataloaders()\n",
    "_, augmented_dataloader = get_imagenet_dataloaders()\n",
    "val_dataset_size = len(val_dataloader.dataset)\n",
    "class_names = val_dataloader.dataset.classes\n",
    "# this maps real classes on top of imagenet's synset format\n",
    "class_names = [real_class_names[c] for c in class_names]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now we duplicate the val_dataloader and create an augmented one\n",
    "# Note that p=1.0 since we want to apply those to entire dataset\n",
    "augmentaions = [\n",
    "    A.RandomBrightnessContrast(p=1.0),\n",
    "    A.ShiftScaleRotate(p=1.0),\n",
    "    A.HueSaturationValue(p=1.0),\n",
    "    A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=1.0),\n",
    "    A.RandomBrightnessContrast(p=1.0),\n",
    "]\n",
    "for a in augmentaions:\n",
    "    augmented_dataloader.\n",
    "    baseline_ds = VisionDataset(val_dataloader)\n",
    "    aug_ds = VisionDataset(augmented_dataloader)\n",
    "\n",
    "    ## Running peformance report on classification\n",
    "    check = PerformanceReport(label_map=class_names)\n",
    "    result = check.run(baseline_ds, aug_ds, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}