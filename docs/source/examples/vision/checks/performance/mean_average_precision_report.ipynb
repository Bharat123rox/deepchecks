{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e767e792",
   "metadata": {},
   "source": [
    "# Mean Average Precision Report\n",
    "\n",
    "This notebooks provides an overview for using and understanding the mean average precision report check.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "- [What is the purpose of the check?](#purpose)\n",
    "- [Generate data & model](#generate)\n",
    "- [Defining the Prediction Formatter](#pred_format)\n",
    "- [Run the check](#run_check)\n",
    "- [Define a condition](#define_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba23c4",
   "metadata": {},
   "source": [
    "## What is the purpose of the check? <a name='purpose'></a>\n",
    "\n",
    "The mean average precision report evaluates the mean average precision metric on the given model and data. \n",
    "The check only works on object detection as it computes the value with the IoU and Area size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7ee01-6999-465e-a318-56570b008526",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bef717-c573-43ec-8589-a81ecc08f2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from deepchecks.vision.base import VisionData\n",
    "from deepchecks.vision.checks.performance import MeanAveragePrecisionReport\n",
    "from deepchecks.vision.datasets.classification import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58d486",
   "metadata": {},
   "source": [
    "### Generate Data and Model <a name='generate'></a>\n",
    "\n",
    "We generate a sample dataset of 128 images from the [COCO dataset](https://cocodataset.org/#home), and using the [YOLOv5 model](https://github.com/ultralytics/yolov5).\n",
    "\n",
    "For the label formatter - our dataset returns exactly the accepted format, so our formatting function is the simple `lambda x: x` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a105788-e0b1-42cc-94cc-fe0292fdaa70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yolo = mnist.load_model(pretrained=True)\n",
    "\n",
    "test_ds = mnist.load_dataset(train=False, object_type='VisionData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e92be5-5c7c-46b7-9e9a-43c30ff87168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepchecks.vision.datasets.classification.mnist.MNISTData at 0x7fd549e9e220>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0509e695-24f3-4d22-872d-ad9bad5f38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.vision import Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1008328",
   "metadata": {},
   "source": [
    "### Run the check <a name='run_check'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81821ee9-2c46-446a-92fc-142b855f833e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ahh - Train:   0%|          | 0/10 [00:00<?, ? Check/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mahhh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fce5f75fe94b91bf3949e8068bd803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n        <h1 id=\"summary_L34LZ\">ahh</h1>\\n        <p>\\n            The suite is co…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = Suite('ahh', MeanAveragePrecisionReport())\n",
    "result = check.run(test_ds, model=yolo)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376fefe0-79a8-438d-8105-945c03964cea",
   "metadata": {},
   "source": [
    "### Observe the check’s output\n",
    "\n",
    "The result value is a dataframe that has the average precision score per each area range and IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd5d0e0-68ff-4536-a6d6-3f8c3cd0b4e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T12:03:26.740693Z",
     "iopub.status.busy": "2022-02-21T12:03:26.740453Z",
     "iopub.status.idle": "2022-02-21T12:03:26.750966Z",
     "shell.execute_reply": "2022-02-21T12:03:26.750380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mAP@0.5..0.95 (%)</th>\n",
       "      <th>AP@.50 (%)</th>\n",
       "      <th>AP@.75 (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.409436</td>\n",
       "      <td>0.566673</td>\n",
       "      <td>0.425339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Small (area &lt; 32^2)</th>\n",
       "      <td>0.212816</td>\n",
       "      <td>0.342429</td>\n",
       "      <td>0.212868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium (32^2 &lt; area &lt; 96^2)</th>\n",
       "      <td>0.383089</td>\n",
       "      <td>0.600228</td>\n",
       "      <td>0.349863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Large (area &lt; 96^2)</th>\n",
       "      <td>0.541146</td>\n",
       "      <td>0.674493</td>\n",
       "      <td>0.585378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mAP@0.5..0.95 (%)  AP@.50 (%)  AP@.75 (%)\n",
       "Area size                                                             \n",
       "All                                   0.409436    0.566673    0.425339\n",
       "Small (area < 32^2)                   0.212816    0.342429    0.212868\n",
       "Medium (32^2 < area < 96^2)           0.383089    0.600228    0.349863\n",
       "Large (area < 96^2)                   0.541146    0.674493    0.585378"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f911b-a833-40d8-b797-9c05edf695d5",
   "metadata": {},
   "source": [
    "## Define a condition <a name='define_condition'></a>\n",
    "\n",
    "We can define a condition that enforce our model's average precision score is not less than a given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b389e9c-a0f7-4676-891d-f1d27a717cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T12:03:26.754084Z",
     "iopub.status.busy": "2022-02-21T12:03:26.753869Z",
     "iopub.status.idle": "2022-02-21T12:03:59.675900Z",
     "shell.execute_reply": "2022-02-21T12:03:59.674967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Mean Average Precision Report</h4><p>Summarize mean average precision metrics on a dataset and model per IoU and area range. <a href=\"https://docs.deepchecks.com/en/0.5.0.dev2/examples/vision/checks/performance/mean_average_precision_report.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Conditions Summary</h5><style type=\"text/css\">\n",
       "#T_b2456_ table {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_b2456_ thead {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_b2456_ tbody {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_b2456_ th {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_b2456_ td {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b2456_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Status</th>\n",
       "      <th class=\"col_heading level0 col1\" >Condition</th>\n",
       "      <th class=\"col_heading level0 col2\" >More Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b2456_row0_col0\" class=\"data row0 col0\" ><div style=\"color: red;text-align: center\">✖</div></td>\n",
       "      <td id=\"T_b2456_row0_col1\" class=\"data row0 col1\" >Scores are not less than 0.4</td>\n",
       "      <td id=\"T_b2456_row0_col2\" class=\"data row0 col2\" >Found scores below threshold:\n",
       "{'Small (area < 32^2)': {'AP@.50 (%)': '0.342'}, 'Medium (32^2 < area < 96^2)': {'AP@.75 (%)': '0.35'}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = MeanAveragePrecisionReport().add_condition_test_average_precision_not_less_than(0.4)\n",
    "result = check.run(test_ds, yolo)\n",
    "result.show(show_additional_outputs=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepchecks-env",
   "language": "python",
   "name": "deepchecks-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
